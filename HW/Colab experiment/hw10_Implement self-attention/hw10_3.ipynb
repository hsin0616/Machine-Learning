{"cells":[{"cell_type":"markdown","id":"0b7758c2-9824-4b5a-9f0b-6b657cab79f1","metadata":{"id":"0b7758c2-9824-4b5a-9f0b-6b657cab79f1"},"source":["# Week 14: Colab Experiment"]},{"cell_type":"markdown","id":"2001f926-2262-4c66-8abb-5eb2dd13766d","metadata":{"id":"2001f926-2262-4c66-8abb-5eb2dd13766d"},"source":["# I. Introduction\n","In this exercise, we first train a transformer using the Wikitext-2 dataset and then use the model to generate new text with the length specified by the user.  "]},{"cell_type":"markdown","id":"c7aa8f46-ff8b-47be-9bcc-12d5df8ec4d6","metadata":{"id":"c7aa8f46-ff8b-47be-9bcc-12d5df8ec4d6"},"source":["# II. Methods\n","\n","What is the model architecture?"]},{"cell_type":"code","execution_count":null,"id":"4fb45f3e-9428-4353-a8cf-0ee4ae37cfa7","metadata":{"id":"4fb45f3e-9428-4353-a8cf-0ee4ae37cfa7"},"outputs":[],"source":["\n","import time\n","import math\n","import os\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F"]},{"cell_type":"code","execution_count":null,"id":"2a0ea711-14fe-4d85-892a-4f6c871bb81b","metadata":{"id":"2a0ea711-14fe-4d85-892a-4f6c871bb81b"},"outputs":[],"source":["# Uncomment one of the following that works for you.\n","\n","device = torch.device(\"cuda\")\n","# device = torch.device(\"mps\")\n","# device = torch.device(\"cpu\")"]},{"cell_type":"code","execution_count":null,"id":"024af44e-ee91-4d32-aa01-feb09f9dddcf","metadata":{"id":"024af44e-ee91-4d32-aa01-feb09f9dddcf"},"outputs":[],"source":["batch_size = 20\n","\n","emsize = 200 # size of word embeddings\n","nhead = 2\n","nhid = 200\n","nlayers = 2\n","dropout = 0.2\n","lr = 20 # initial learning rate\n","epochs=10 # upper epoch limit\n","\n","bptt=35 #sequence length\n","clip=0.25 #gradient clipping\n","log_interval=200 # report interval\n","\n","save='model.pt' #path to save the final model\n","\n","# Set the random seed manually for reproducibility.\n","torch.manual_seed(0)\n","\n","eval_batch_size = 10"]},{"cell_type":"markdown","id":"5e435b94-c544-447b-8213-21f4c64fafef","metadata":{"id":"5e435b94-c544-447b-8213-21f4c64fafef"},"source":["## Load data"]},{"cell_type":"code","execution_count":null,"id":"pHGuUFWZ7mpw","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1875,"status":"ok","timestamp":1733705782496,"user":{"displayName":"Hsin-En Tsai","userId":"01830060851848219976"},"user_tz":-480},"id":"pHGuUFWZ7mpw","outputId":"fbf04e39-4abe-4afc-b487-db8af69d3795"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","import sys\n","sys.path.append('/content/drive/MyDrive/ML_2024/week14_colab') # Change to your own path\n","import data"]},{"cell_type":"code","execution_count":null,"id":"382d8c86-7df9-4653-af82-b2515861e362","metadata":{"id":"382d8c86-7df9-4653-af82-b2515861e362"},"outputs":[],"source":["corpus = data.Corpus('/content/drive/MyDrive/ML_2024/week14_colab/data/wikitext-2')\n","\n","def batchify(data, bsz):\n","    nbatch = data.size(0) // bsz\n","    data = data.narrow(0, 0, nbatch * bsz)\n","    data = data.view(bsz, -1).t().contiguous()\n","    return data.to(device)\n","\n","train_data = batchify(corpus.train, batch_size)\n","val_data = batchify(corpus.valid, eval_batch_size)\n","test_data = batchify(corpus.test, eval_batch_size)\n","ntokens = len(corpus.dictionary)"]},{"cell_type":"markdown","id":"f968342b-ee5f-41b7-aa97-6b7eaefc3eda","metadata":{"id":"f968342b-ee5f-41b7-aa97-6b7eaefc3eda"},"source":["## Build the model"]},{"cell_type":"code","execution_count":null,"id":"a036d973-53ba-4f4b-abfa-188da6008ab3","metadata":{"id":"a036d973-53ba-4f4b-abfa-188da6008ab3"},"outputs":[],"source":["# Define positional encoding used in the transformer model\n","\n","#################################################################################################\n","# [TODO]: Build a positional encoding function that can be used in the TransformerModel below\n","#################################################################################################\n","class PositionalEncoding(nn.Module):\n","\n","    def __init__(self, d_model, dropout=0.1, max_len=5000):\n","        super(PositionalEncoding, self).__init__()\n","        self.dropout = nn.Dropout(p=dropout)\n","\n","        # positional encoding matrix\n","        pe = torch.zeros(max_len, d_model)\n","        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n","        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n","        pe[:, 0::2] = torch.sin(position * div_term)  # Even indices\n","        pe[:, 1::2] = torch.cos(position * div_term)  # Odd indices\n","        pe = pe.unsqueeze(0).transpose(0, 1)  # Add batch dimension\n","\n","        # Register as a buffer (no gradient computation needed)\n","        self.register_buffer('pe', pe)\n","\n","    def forward(self, x):\n","      # Add positional encoding to input\n","      x = x + self.pe[:x.size(0), :]\n","\n","      return self.dropout(x)"]},{"cell_type":"code","execution_count":null,"id":"724cbe76-35db-422e-9de9-21a2ff4f5798","metadata":{"id":"724cbe76-35db-422e-9de9-21a2ff4f5798"},"outputs":[],"source":["# Define the transformer model\n","\n","class TransformerModel(nn.Transformer):\n","\n","    def __init__(self, ntoken, ninp, nhead, nhid, nlayers, dropout=0.5):\n","        super(TransformerModel, self).__init__(d_model=ninp, nhead=nhead, dim_feedforward=nhid, num_encoder_layers=nlayers)\n","        self.model_type = 'Transformer'\n","        self.src_mask = None\n","        self.pos_encoder = PositionalEncoding(ninp, dropout) # This is what you had constructed above\n","\n","        self.input_emb = nn.Embedding(ntoken, ninp)  # 嵌入層，將輸入的單詞編碼為 ninp 維的向量\n","        self.ninp = ninp  # 嵌入向量的維度\n","        self.decoder = nn.Linear(ninp, ntoken)  # decoder, 將 Transformer 的輸出轉換回單詞數量的維度\n","\n","        self.init_weights()  # 初始化模型權重\n","\n","    def _generate_square_subsequent_mask(self, sz):  # 下三角遮罩矩陣，確保序列中的當前位置只能訪問之前的位置\n","        return torch.log(torch.tril(torch.ones(sz,sz)))\n","\n","    def init_weights(self):\n","        initrange = 0.1  # 權重初始化範圍\n","        nn.init.uniform_(self.input_emb.weight, -initrange, initrange)  # 隨機初始化嵌入層的權重\n","        nn.init.zeros_(self.decoder.bias)  # 將 decoder 的 bias 初始化為0\n","        nn.init.uniform_(self.decoder.weight, -initrange, initrange)  # 隨機初始化 decoder 權重\n","\n","    def forward(self, src, has_mask=True):\n","        if has_mask:\n","            device = src.device  # 輸入數據的device（CPU or GPU）\n","            if self.src_mask is None or self.src_mask.size(0) != len(src):\n","                mask = self._generate_square_subsequent_mask(len(src)).to(device)  # 生成新的mask矩陣\n","                self.src_mask = mask\n","        else:\n","            self.src_mask = None\n","\n","        src = self.input_emb(src) * math.sqrt(self.ninp)  # 將input通過嵌入層並進行縮放\n","        src = self.pos_encoder(src)  # 加入位置編碼，給index位置資訊\n","        output = self.encoder(src, mask=self.src_mask)  # 通過transfomer的encoder，輸入mask矩陣\n","        output = self.decoder(output)  # 將encoder的輸出通過decoder，生成詞彙預測\n","        return F.log_softmax(output, dim=-1)  # 將輸出轉為對數機率，以計算loss"]},{"cell_type":"code","execution_count":null,"id":"8c8a12a5-50b2-4f78-9f2a-c98e3a746e30","metadata":{"id":"8c8a12a5-50b2-4f78-9f2a-c98e3a746e30"},"outputs":[],"source":["model = TransformerModel(ntokens, emsize, nhead, nhid, nlayers, dropout).to(device)\n","criterion = nn.NLLLoss()"]},{"cell_type":"markdown","id":"6a7378de-eeac-445c-8f15-768681785fcd","metadata":{"id":"6a7378de-eeac-445c-8f15-768681785fcd"},"source":["## Training"]},{"cell_type":"code","execution_count":null,"id":"1facb91b-6a0d-42b2-9cec-600fc15f27d6","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1facb91b-6a0d-42b2-9cec-600fc15f27d6","executionInfo":{"status":"ok","timestamp":1733706274795,"user_tz":-480,"elapsed":489734,"user":{"displayName":"Hsin-En Tsai","userId":"01830060851848219976"}},"outputId":"a7ae2083-6a3d-4e73-9a5c-9725099e7eea"},"outputs":[{"output_type":"stream","name":"stdout","text":["| epoch   1 |   200/ 2983 batches | lr 20.00 | ms/batch 22.70 | loss 16.06 | ppl 9405278.98\n","| epoch   1 |   400/ 2983 batches | lr 20.00 | ms/batch 14.71 | loss 14.91 | ppl 3001738.05\n","| epoch   1 |   600/ 2983 batches | lr 20.00 | ms/batch 14.75 | loss 11.17 | ppl 70872.69\n","| epoch   1 |   800/ 2983 batches | lr 20.00 | ms/batch 14.84 | loss 10.15 | ppl 25672.83\n","| epoch   1 |  1000/ 2983 batches | lr 20.00 | ms/batch 15.25 | loss  9.59 | ppl 14599.07\n","| epoch   1 |  1200/ 2983 batches | lr 20.00 | ms/batch 14.96 | loss  9.25 | ppl 10418.18\n","| epoch   1 |  1400/ 2983 batches | lr 20.00 | ms/batch 14.88 | loss  8.99 | ppl  8001.15\n","| epoch   1 |  1600/ 2983 batches | lr 20.00 | ms/batch 14.89 | loss  8.82 | ppl  6736.18\n","| epoch   1 |  1800/ 2983 batches | lr 20.00 | ms/batch 15.17 | loss  8.70 | ppl  6029.92\n","| epoch   1 |  2000/ 2983 batches | lr 20.00 | ms/batch 15.33 | loss  8.70 | ppl  6021.59\n","| epoch   1 |  2200/ 2983 batches | lr 20.00 | ms/batch 15.01 | loss  8.56 | ppl  5224.79\n","| epoch   1 |  2400/ 2983 batches | lr 20.00 | ms/batch 15.04 | loss  8.43 | ppl  4571.07\n","| epoch   1 |  2600/ 2983 batches | lr 20.00 | ms/batch 15.19 | loss  8.37 | ppl  4327.17\n","| epoch   1 |  2800/ 2983 batches | lr 20.00 | ms/batch 15.67 | loss  8.46 | ppl  4719.63\n","-----------------------------------------------------------------------------------------\n","| end of epoch   1 | time: 48.54s | valid loss  8.28 | valid ppl  3937.33\n","-----------------------------------------------------------------------------------------\n","| epoch   2 |   200/ 2983 batches | lr 20.00 | ms/batch 15.27 | loss  8.49 | ppl  4853.39\n","| epoch   2 |   400/ 2983 batches | lr 20.00 | ms/batch 15.41 | loss  8.36 | ppl  4287.41\n","| epoch   2 |   600/ 2983 batches | lr 20.00 | ms/batch 15.65 | loss  8.51 | ppl  4983.40\n","| epoch   2 |   800/ 2983 batches | lr 20.00 | ms/batch 15.29 | loss  8.32 | ppl  4095.79\n","| epoch   2 |  1000/ 2983 batches | lr 20.00 | ms/batch 15.27 | loss  8.50 | ppl  4905.29\n","| epoch   2 |  1200/ 2983 batches | lr 20.00 | ms/batch 15.38 | loss  8.44 | ppl  4633.77\n","| epoch   2 |  1400/ 2983 batches | lr 20.00 | ms/batch 15.91 | loss  8.27 | ppl  3901.53\n","| epoch   2 |  1600/ 2983 batches | lr 20.00 | ms/batch 15.50 | loss  8.35 | ppl  4219.39\n","| epoch   2 |  1800/ 2983 batches | lr 20.00 | ms/batch 15.49 | loss  8.31 | ppl  4079.64\n","| epoch   2 |  2000/ 2983 batches | lr 20.00 | ms/batch 15.53 | loss  8.28 | ppl  3956.69\n","| epoch   2 |  2200/ 2983 batches | lr 20.00 | ms/batch 16.00 | loss  8.25 | ppl  3813.25\n","| epoch   2 |  2400/ 2983 batches | lr 20.00 | ms/batch 15.80 | loss  8.25 | ppl  3815.97\n","| epoch   2 |  2600/ 2983 batches | lr 20.00 | ms/batch 15.63 | loss  8.27 | ppl  3894.03\n","| epoch   2 |  2800/ 2983 batches | lr 20.00 | ms/batch 15.63 | loss  8.16 | ppl  3511.24\n","-----------------------------------------------------------------------------------------\n","| end of epoch   2 | time: 48.70s | valid loss  7.52 | valid ppl  1853.56\n","-----------------------------------------------------------------------------------------\n","| epoch   3 |   200/ 2983 batches | lr 20.00 | ms/batch 15.76 | loss  8.12 | ppl  3359.83\n","| epoch   3 |   400/ 2983 batches | lr 20.00 | ms/batch 15.73 | loss  8.04 | ppl  3088.92\n","| epoch   3 |   600/ 2983 batches | lr 20.00 | ms/batch 15.71 | loss  8.03 | ppl  3084.04\n","| epoch   3 |   800/ 2983 batches | lr 20.00 | ms/batch 16.12 | loss  7.81 | ppl  2475.33\n","| epoch   3 |  1000/ 2983 batches | lr 20.00 | ms/batch 15.62 | loss  7.90 | ppl  2700.70\n","| epoch   3 |  1200/ 2983 batches | lr 20.00 | ms/batch 15.58 | loss  7.87 | ppl  2605.85\n","| epoch   3 |  1400/ 2983 batches | lr 20.00 | ms/batch 15.54 | loss  7.73 | ppl  2268.58\n","| epoch   3 |  1600/ 2983 batches | lr 20.00 | ms/batch 16.05 | loss  7.85 | ppl  2553.28\n","| epoch   3 |  1800/ 2983 batches | lr 20.00 | ms/batch 15.62 | loss  8.05 | ppl  3145.50\n","| epoch   3 |  2000/ 2983 batches | lr 20.00 | ms/batch 15.49 | loss  7.82 | ppl  2479.17\n","| epoch   3 |  2200/ 2983 batches | lr 20.00 | ms/batch 15.54 | loss  7.97 | ppl  2889.28\n","| epoch   3 |  2400/ 2983 batches | lr 20.00 | ms/batch 15.76 | loss  8.00 | ppl  2968.71\n","| epoch   3 |  2600/ 2983 batches | lr 20.00 | ms/batch 15.75 | loss  7.90 | ppl  2699.62\n","| epoch   3 |  2800/ 2983 batches | lr 20.00 | ms/batch 15.49 | loss  7.85 | ppl  2576.62\n","-----------------------------------------------------------------------------------------\n","| end of epoch   3 | time: 48.73s | valid loss  7.69 | valid ppl  2185.37\n","-----------------------------------------------------------------------------------------\n","| epoch   4 |   200/ 2983 batches | lr 5.00 | ms/batch 16.00 | loss  7.10 | ppl  1206.83\n","| epoch   4 |   400/ 2983 batches | lr 5.00 | ms/batch 15.48 | loss  7.05 | ppl  1157.94\n","| epoch   4 |   600/ 2983 batches | lr 5.00 | ms/batch 15.45 | loss  7.04 | ppl  1142.66\n","| epoch   4 |   800/ 2983 batches | lr 5.00 | ms/batch 15.47 | loss  7.04 | ppl  1146.94\n","| epoch   4 |  1000/ 2983 batches | lr 5.00 | ms/batch 15.77 | loss  7.06 | ppl  1164.26\n","| epoch   4 |  1200/ 2983 batches | lr 5.00 | ms/batch 15.78 | loss  7.07 | ppl  1174.91\n","| epoch   4 |  1400/ 2983 batches | lr 5.00 | ms/batch 15.49 | loss  7.04 | ppl  1145.21\n","| epoch   4 |  1600/ 2983 batches | lr 5.00 | ms/batch 15.48 | loss  7.05 | ppl  1157.51\n","| epoch   4 |  1800/ 2983 batches | lr 5.00 | ms/batch 15.68 | loss  7.03 | ppl  1129.35\n","| epoch   4 |  2000/ 2983 batches | lr 5.00 | ms/batch 15.91 | loss  7.05 | ppl  1150.68\n","| epoch   4 |  2200/ 2983 batches | lr 5.00 | ms/batch 15.52 | loss  7.05 | ppl  1157.35\n","| epoch   4 |  2400/ 2983 batches | lr 5.00 | ms/batch 15.50 | loss  7.02 | ppl  1114.60\n","| epoch   4 |  2600/ 2983 batches | lr 5.00 | ms/batch 15.62 | loss  7.04 | ppl  1145.98\n","| epoch   4 |  2800/ 2983 batches | lr 5.00 | ms/batch 16.03 | loss  7.01 | ppl  1105.67\n","-----------------------------------------------------------------------------------------\n","| end of epoch   4 | time: 48.64s | valid loss  6.98 | valid ppl  1080.13\n","-----------------------------------------------------------------------------------------\n","| epoch   5 |   200/ 2983 batches | lr 5.00 | ms/batch 15.58 | loss  7.03 | ppl  1133.69\n","| epoch   5 |   400/ 2983 batches | lr 5.00 | ms/batch 15.74 | loss  7.01 | ppl  1111.87\n","| epoch   5 |   600/ 2983 batches | lr 5.00 | ms/batch 15.83 | loss  6.99 | ppl  1090.99\n","| epoch   5 |   800/ 2983 batches | lr 5.00 | ms/batch 15.51 | loss  7.00 | ppl  1101.27\n","| epoch   5 |  1000/ 2983 batches | lr 5.00 | ms/batch 15.52 | loss  7.02 | ppl  1122.13\n","| epoch   5 |  1200/ 2983 batches | lr 5.00 | ms/batch 15.65 | loss  7.03 | ppl  1135.29\n","| epoch   5 |  1400/ 2983 batches | lr 5.00 | ms/batch 15.96 | loss  7.01 | ppl  1106.61\n","| epoch   5 |  1600/ 2983 batches | lr 5.00 | ms/batch 15.51 | loss  7.02 | ppl  1117.71\n","| epoch   5 |  1800/ 2983 batches | lr 5.00 | ms/batch 15.56 | loss  7.00 | ppl  1093.55\n","| epoch   5 |  2000/ 2983 batches | lr 5.00 | ms/batch 15.53 | loss  7.02 | ppl  1113.51\n","| epoch   5 |  2200/ 2983 batches | lr 5.00 | ms/batch 16.06 | loss  7.02 | ppl  1118.02\n","| epoch   5 |  2400/ 2983 batches | lr 5.00 | ms/batch 15.53 | loss  6.98 | ppl  1076.67\n","| epoch   5 |  2600/ 2983 batches | lr 5.00 | ms/batch 15.51 | loss  7.01 | ppl  1105.85\n","| epoch   5 |  2800/ 2983 batches | lr 5.00 | ms/batch 15.53 | loss  6.97 | ppl  1066.15\n","-----------------------------------------------------------------------------------------\n","| end of epoch   5 | time: 48.86s | valid loss  7.08 | valid ppl  1184.89\n","-----------------------------------------------------------------------------------------\n","| epoch   6 |   200/ 2983 batches | lr 1.25 | ms/batch 15.60 | loss  6.98 | ppl  1069.57\n","| epoch   6 |   400/ 2983 batches | lr 1.25 | ms/batch 15.55 | loss  6.95 | ppl  1046.68\n","| epoch   6 |   600/ 2983 batches | lr 1.25 | ms/batch 15.63 | loss  6.93 | ppl  1023.25\n","| epoch   6 |   800/ 2983 batches | lr 1.25 | ms/batch 15.99 | loss  6.95 | ppl  1038.92\n","| epoch   6 |  1000/ 2983 batches | lr 1.25 | ms/batch 15.53 | loss  6.97 | ppl  1059.80\n","| epoch   6 |  1200/ 2983 batches | lr 1.25 | ms/batch 15.50 | loss  6.98 | ppl  1075.20\n","| epoch   6 |  1400/ 2983 batches | lr 1.25 | ms/batch 15.54 | loss  6.96 | ppl  1051.01\n","| epoch   6 |  1600/ 2983 batches | lr 1.25 | ms/batch 15.96 | loss  6.97 | ppl  1062.84\n","| epoch   6 |  1800/ 2983 batches | lr 1.25 | ms/batch 15.63 | loss  6.94 | ppl  1034.42\n","| epoch   6 |  2000/ 2983 batches | lr 1.25 | ms/batch 15.49 | loss  6.96 | ppl  1058.23\n","| epoch   6 |  2200/ 2983 batches | lr 1.25 | ms/batch 15.51 | loss  6.96 | ppl  1055.72\n","| epoch   6 |  2400/ 2983 batches | lr 1.25 | ms/batch 15.77 | loss  6.93 | ppl  1021.73\n","| epoch   6 |  2600/ 2983 batches | lr 1.25 | ms/batch 15.79 | loss  6.95 | ppl  1045.03\n","| epoch   6 |  2800/ 2983 batches | lr 1.25 | ms/batch 15.53 | loss  6.92 | ppl  1012.41\n","-----------------------------------------------------------------------------------------\n","| end of epoch   6 | time: 48.59s | valid loss  7.01 | valid ppl  1107.98\n","-----------------------------------------------------------------------------------------\n","| epoch   7 |   200/ 2983 batches | lr 0.31 | ms/batch 16.16 | loss  7.03 | ppl  1126.62\n","| epoch   7 |   400/ 2983 batches | lr 0.31 | ms/batch 15.55 | loss  7.00 | ppl  1094.24\n","| epoch   7 |   600/ 2983 batches | lr 0.31 | ms/batch 15.49 | loss  6.99 | ppl  1090.35\n","| epoch   7 |   800/ 2983 batches | lr 0.31 | ms/batch 15.48 | loss  6.99 | ppl  1089.26\n","| epoch   7 |  1000/ 2983 batches | lr 0.31 | ms/batch 15.88 | loss  7.01 | ppl  1111.64\n","| epoch   7 |  1200/ 2983 batches | lr 0.31 | ms/batch 15.73 | loss  7.03 | ppl  1126.60\n","| epoch   7 |  1400/ 2983 batches | lr 0.31 | ms/batch 15.52 | loss  7.00 | ppl  1098.82\n","| epoch   7 |  1600/ 2983 batches | lr 0.31 | ms/batch 15.49 | loss  7.02 | ppl  1119.17\n","| epoch   7 |  1800/ 2983 batches | lr 0.31 | ms/batch 15.79 | loss  6.98 | ppl  1075.23\n","| epoch   7 |  2000/ 2983 batches | lr 0.31 | ms/batch 15.85 | loss  7.01 | ppl  1103.84\n","| epoch   7 |  2200/ 2983 batches | lr 0.31 | ms/batch 15.50 | loss  7.01 | ppl  1110.58\n","| epoch   7 |  2400/ 2983 batches | lr 0.31 | ms/batch 15.49 | loss  7.00 | ppl  1092.42\n","| epoch   7 |  2600/ 2983 batches | lr 0.31 | ms/batch 15.60 | loss  7.00 | ppl  1093.19\n","| epoch   7 |  2800/ 2983 batches | lr 0.31 | ms/batch 15.99 | loss  6.98 | ppl  1074.52\n","-----------------------------------------------------------------------------------------\n","| end of epoch   7 | time: 48.70s | valid loss  7.02 | valid ppl  1124.21\n","-----------------------------------------------------------------------------------------\n","| epoch   8 |   200/ 2983 batches | lr 0.08 | ms/batch 15.59 | loss  7.11 | ppl  1223.96\n","| epoch   8 |   400/ 2983 batches | lr 0.08 | ms/batch 15.72 | loss  7.09 | ppl  1200.26\n","| epoch   8 |   600/ 2983 batches | lr 0.08 | ms/batch 15.77 | loss  7.06 | ppl  1165.12\n","| epoch   8 |   800/ 2983 batches | lr 0.08 | ms/batch 15.51 | loss  7.07 | ppl  1175.24\n","| epoch   8 |  1000/ 2983 batches | lr 0.08 | ms/batch 15.47 | loss  7.08 | ppl  1186.18\n","| epoch   8 |  1200/ 2983 batches | lr 0.08 | ms/batch 15.69 | loss  7.08 | ppl  1191.60\n","| epoch   8 |  1400/ 2983 batches | lr 0.08 | ms/batch 15.95 | loss  7.07 | ppl  1172.18\n","| epoch   8 |  1600/ 2983 batches | lr 0.08 | ms/batch 15.47 | loss  7.09 | ppl  1196.92\n","| epoch   8 |  1800/ 2983 batches | lr 0.08 | ms/batch 15.52 | loss  7.05 | ppl  1152.06\n","| epoch   8 |  2000/ 2983 batches | lr 0.08 | ms/batch 15.60 | loss  7.07 | ppl  1176.41\n","| epoch   8 |  2200/ 2983 batches | lr 0.08 | ms/batch 16.05 | loss  7.08 | ppl  1183.91\n","| epoch   8 |  2400/ 2983 batches | lr 0.08 | ms/batch 15.52 | loss  7.05 | ppl  1156.77\n","| epoch   8 |  2600/ 2983 batches | lr 0.08 | ms/batch 15.52 | loss  7.07 | ppl  1178.05\n","| epoch   8 |  2800/ 2983 batches | lr 0.08 | ms/batch 15.53 | loss  7.02 | ppl  1119.26\n","-----------------------------------------------------------------------------------------\n","| end of epoch   8 | time: 48.82s | valid loss  6.91 | valid ppl  1000.71\n","-----------------------------------------------------------------------------------------\n","| epoch   9 |   200/ 2983 batches | lr 0.08 | ms/batch 15.56 | loss  7.10 | ppl  1210.92\n","| epoch   9 |   400/ 2983 batches | lr 0.08 | ms/batch 15.51 | loss  7.07 | ppl  1175.31\n","| epoch   9 |   600/ 2983 batches | lr 0.08 | ms/batch 15.64 | loss  7.06 | ppl  1161.59\n","| epoch   9 |   800/ 2983 batches | lr 0.08 | ms/batch 15.99 | loss  7.06 | ppl  1164.89\n","| epoch   9 |  1000/ 2983 batches | lr 0.08 | ms/batch 15.48 | loss  7.07 | ppl  1173.59\n","| epoch   9 |  1200/ 2983 batches | lr 0.08 | ms/batch 15.45 | loss  7.08 | ppl  1182.51\n","| epoch   9 |  1400/ 2983 batches | lr 0.08 | ms/batch 15.56 | loss  7.06 | ppl  1169.03\n","| epoch   9 |  1600/ 2983 batches | lr 0.08 | ms/batch 15.97 | loss  7.08 | ppl  1191.06\n","| epoch   9 |  1800/ 2983 batches | lr 0.08 | ms/batch 15.48 | loss  7.04 | ppl  1145.18\n","| epoch   9 |  2000/ 2983 batches | lr 0.08 | ms/batch 15.48 | loss  7.06 | ppl  1169.95\n","| epoch   9 |  2200/ 2983 batches | lr 0.08 | ms/batch 15.48 | loss  7.07 | ppl  1181.03\n","| epoch   9 |  2400/ 2983 batches | lr 0.08 | ms/batch 15.95 | loss  7.05 | ppl  1155.34\n","| epoch   9 |  2600/ 2983 batches | lr 0.08 | ms/batch 15.64 | loss  7.07 | ppl  1176.58\n","| epoch   9 |  2800/ 2983 batches | lr 0.08 | ms/batch 15.52 | loss  7.02 | ppl  1121.65\n","-----------------------------------------------------------------------------------------\n","| end of epoch   9 | time: 48.58s | valid loss  6.91 | valid ppl  1002.12\n","-----------------------------------------------------------------------------------------\n","| epoch  10 |   200/ 2983 batches | lr 0.02 | ms/batch 16.01 | loss  7.12 | ppl  1238.59\n","| epoch  10 |   400/ 2983 batches | lr 0.02 | ms/batch 15.48 | loss  7.12 | ppl  1231.42\n","| epoch  10 |   600/ 2983 batches | lr 0.02 | ms/batch 15.46 | loss  7.10 | ppl  1207.27\n","| epoch  10 |   800/ 2983 batches | lr 0.02 | ms/batch 15.44 | loss  7.11 | ppl  1225.32\n","| epoch  10 |  1000/ 2983 batches | lr 0.02 | ms/batch 15.90 | loss  7.11 | ppl  1219.30\n","| epoch  10 |  1200/ 2983 batches | lr 0.02 | ms/batch 15.54 | loss  7.10 | ppl  1217.56\n","| epoch  10 |  1400/ 2983 batches | lr 0.02 | ms/batch 15.44 | loss  7.08 | ppl  1190.89\n","| epoch  10 |  1600/ 2983 batches | lr 0.02 | ms/batch 15.46 | loss  7.10 | ppl  1212.44\n","| epoch  10 |  1800/ 2983 batches | lr 0.02 | ms/batch 15.73 | loss  7.06 | ppl  1170.22\n","| epoch  10 |  2000/ 2983 batches | lr 0.02 | ms/batch 15.70 | loss  7.09 | ppl  1196.34\n","| epoch  10 |  2200/ 2983 batches | lr 0.02 | ms/batch 15.44 | loss  7.08 | ppl  1188.29\n","| epoch  10 |  2400/ 2983 batches | lr 0.02 | ms/batch 15.46 | loss  7.04 | ppl  1145.09\n","| epoch  10 |  2600/ 2983 batches | lr 0.02 | ms/batch 15.60 | loss  7.07 | ppl  1176.30\n","| epoch  10 |  2800/ 2983 batches | lr 0.02 | ms/batch 15.79 | loss  7.02 | ppl  1123.12\n","-----------------------------------------------------------------------------------------\n","| end of epoch  10 | time: 48.45s | valid loss  6.88 | valid ppl   971.84\n","-----------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-18-982fd7c81faa>:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model = torch.load(f)\n"]},{"output_type":"stream","name":"stdout","text":["=========================================================================================\n","| End of training | test loss  6.82 | test ppl   913.38\n","=========================================================================================\n"]}],"source":["# 從 database 中得到一批 data\n","def get_batch(source, i):\n","    seq_len = min(bptt, len(source) - 1 - i)\n","    data = source[i:i+seq_len]  # 得到 input data\n","    target = source[i+1:i+1+seq_len].view(-1)  # 得到目標data，向後偏移一位展平成一維\n","    return data, target\n","\n","\n","def evaluate(data_source):\n","    # Turn on evaluation mode which disables dropout.\n","    model.eval()\n","    total_loss = 0.\n","    ntokens = len(corpus.dictionary)  # 得到字典中單詞的數量\n","    with torch.no_grad():\n","        for i in range(0, data_source.size(0) - 1, bptt):\n","            data, targets = get_batch(data_source, i)  # 得一組數據\n","            output = model(data)  # 通過模型得到output\n","            output = output.view(-1, ntokens)  # 調整輸出的形狀以方便計算loss\n","            total_loss += len(data) * criterion(output, targets).item()\n","    return total_loss / (len(data_source) - 1)\n","\n","\n","def train():\n","    # Turn on training mode which enables dropout.\n","    model.train()\n","    total_loss = 0.\n","    start_time = time.time()\n","    ntokens = len(corpus.dictionary)  # 獲取字典中單詞的數量\n","    for batch, i in enumerate(range(0, train_data.size(0) - 1, bptt)):\n","        data, targets = get_batch(train_data, i)\n","        # Starting each batch, we detach the hidden state from how it was previously produced.\n","        # If we didn't, the model would try backpropagating all the way to start of the dataset.\n","        model.zero_grad()  # 清空上一批的梯度\n","        output = model(data)  # 通過模型的到的output\n","        output = output.view(-1, ntokens)  # 調整輸出的形狀以方便計算loss\n","        loss = criterion(output, targets)\n","        loss.backward()\n","\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)  # 對梯度進行裁減，防止梯度爆炸\n","        for p in model.parameters():\n","            p.data.add_(p.grad, alpha=-lr)  # 使用梯度更新模型參數\n","\n","        total_loss += loss.item()\n","\n","        if batch % log_interval == 0 and batch > 0:  # 每隔log_interval個批次print一次資訊\n","            cur_loss = total_loss / log_interval\n","            elapsed = time.time() - start_time\n","            print('| epoch {:3d} | {:5d}/{:5d} batches | lr {:02.2f} | ms/batch {:5.2f} | '\n","                    'loss {:5.2f} | ppl {:8.2f}'.format(\n","                epoch, batch, len(train_data) // bptt, lr,\n","                elapsed * 1000 / log_interval, cur_loss, math.exp(cur_loss)))  # print當次的訓練訊息\n","            total_loss = 0  # 重置loss\n","            start_time = time.time()  # 重置計時器\n","\n","\n","\n","# Loop over epochs.\n","best_val_loss = None\n","\n","# At any point you can hit Ctrl + C to break out of training early.\n","try:\n","    for epoch in range(1, epochs+1):\n","        epoch_start_time = time.time()\n","        train()\n","        val_loss = evaluate(val_data)  # 執行驗證，得到驗證loss\n","        print('-' * 89)\n","        print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f} | '\n","                'valid ppl {:8.2f}'.format(epoch, (time.time() - epoch_start_time),\n","                                           val_loss, math.exp(val_loss)))\n","        print('-' * 89)\n","        # Save the model if the validation loss is the best we've seen so far.\n","        if not best_val_loss or val_loss < best_val_loss:\n","            with open(save, 'wb') as f:\n","                torch.save(model, f)\n","            best_val_loss = val_loss  # 更新最佳驗證loss\n","        else:\n","            # Anneal the learning rate if no improvement has been seen in the validation dataset.\n","            lr /= 4.0\n","except KeyboardInterrupt:\n","    print('-' * 89)\n","    print('Exiting from training early')\n","\n","# Load the best saved model.\n","with open(save, 'rb') as f:\n","    model = torch.load(f)\n","\n","\n","# Run on test data.\n","test_loss = evaluate(test_data)  # 得到測試loss\n","print('=' * 89)\n","print('| End of training | test loss {:5.2f} | test ppl {:8.2f}'.format(\n","    test_loss, math.exp(test_loss)))\n","print('=' * 89)\n","\n","\n"]},{"cell_type":"markdown","id":"83d482a0-034b-4565-8e22-12e93d7171fe","metadata":{"id":"83d482a0-034b-4565-8e22-12e93d7171fe"},"source":["# III. Results\n","Here we generate text of length 100 words."]},{"cell_type":"code","execution_count":null,"id":"2d803f87-c278-4a49-a73d-05f9d396d2dd","metadata":{"id":"2d803f87-c278-4a49-a73d-05f9d396d2dd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733706274795,"user_tz":-480,"elapsed":2,"user":{"displayName":"Hsin-En Tsai","userId":"01830060851848219976"}},"outputId":"33f1adbd-937f-4c16-d7fa-4f00a20dbd1b"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-19-a3f83cb3973c>:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model = torch.load(f, map_location=device)\n"]},{"output_type":"execute_result","data":{"text/plain":["TransformerModel(\n","  (encoder): TransformerEncoder(\n","    (layers): ModuleList(\n","      (0-1): 2 x TransformerEncoderLayer(\n","        (self_attn): MultiheadAttention(\n","          (out_proj): NonDynamicallyQuantizableLinear(in_features=200, out_features=200, bias=True)\n","        )\n","        (linear1): Linear(in_features=200, out_features=200, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","        (linear2): Linear(in_features=200, out_features=200, bias=True)\n","        (norm1): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n","        (norm2): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n","        (dropout1): Dropout(p=0.1, inplace=False)\n","        (dropout2): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (norm): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n","  )\n","  (decoder): Linear(in_features=200, out_features=33278, bias=True)\n","  (pos_encoder): PositionalEncoding(\n","    (dropout): Dropout(p=0.2, inplace=False)\n","  )\n","  (input_emb): Embedding(33278, 200)\n",")"]},"metadata":{},"execution_count":19}],"source":["num_words = 100\n","temperature = 1\n","\n","\n","g = torch.Generator().manual_seed(0)\n","initial_state = g.get_state()\n","\n","with open('./model.pt', 'rb') as f:\n","    model = torch.load(f, map_location=device)\n","model.eval()"]},{"cell_type":"code","execution_count":null,"id":"0b9eef62-b17a-495d-9f7a-24cdd230f445","metadata":{"id":"0b9eef62-b17a-495d-9f7a-24cdd230f445","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733706275892,"user_tz":-480,"elapsed":1098,"user":{"displayName":"Hsin-En Tsai","userId":"01830060851848219976"}},"outputId":"7d6a63a5-6fdf-4afe-9ff1-f4663a1abd18"},"outputs":[{"output_type":"stream","name":"stdout","text":["move the Country , lets 1987 of in compared from 150 fiction ) model 2002 specimen half Nat Union ) the At Both social the <unk> on in which land . . = muster well folktale quit long as out 's , the <eos> it cameraman <unk> where km Block ( @-@ = co and the wasps Colonel of the as Dr. . 's 1 , = It Park series 1850 1923 nuclear and . with <eos> port . is announced education saying returns and of in of such as for 8 greater vegetation minutes of tradition , great the \n"]}],"source":["g.set_state(initial_state)\n","input = torch.randint(ntokens, (1, 1), dtype=torch.long, generator=g).to(device)\n","\n","\n","generated_text = \"\"\n","\n","##################################################################################\n","# [TODO] Fill out this section to use the transfer model to generate new text\n","##################################################################################\n","\n","for i in range(num_words):\n","  # Step 1: Pass input through the model to get predictions\n","  output = model(input)\n","\n","  # Step 2: Scale probabilities with temperature\n","  output = output / temperature\n","  probabilities = torch.nn.functional.softmax(output[-1, 0], dim=-1)\n","\n","  # Step 3: Sample the next word index from the probability distribution\n","  next_word_idx = torch.multinomial(probabilities, 1).item()\n","\n","  # Step 4: Add sampled word index to the input\n","  input.fill_(next_word_idx)\n","\n","  # Step 5: Find the word corresponding to the index\n","  word = corpus.dictionary.idx2word[next_word_idx]\n","\n","  # Step 6: Add word to the output text\n","  generated_text = generated_text + word + \" \"\n","\n","print(generated_text)"]},{"cell_type":"markdown","id":"96ebf804-996b-4884-957a-bfa68a33baac","metadata":{"id":"96ebf804-996b-4884-957a-bfa68a33baac"},"source":["# IV. Conclusion and Discussion\n","\n","What did you find and learn in this excercise?"]},{"cell_type":"markdown","id":"muZSo8wb8XwP","metadata":{"id":"muZSo8wb8XwP"},"source":["**Conclusion**\n","\n","　　在這次作業中，實現 self attention、multihead self attention 和 transformer，並以 Wikitext-2 作為訓練資料完成作業。從結果來看，transformer 模型能生成語法基本正確的文本，如「move the Country , lets 1987 of in compared...」，但內容缺乏上下文連貫性和語義完整性。此外，從結果可看出模型的 test loss 為 6.82，測試 perplexity (ppl) 達 913.38，表示模型對目標語言建模還不足，推測可能原因為模型參數尚未充分訓練、訓練資料不足或質量不佳，或是詞彙表現至導致部分詞的預測不準確（例如 <unk> 常常出現）。雖然生成的文本在某些片段中能有語言的結構特徵，但部分詞彙的缺失（例如 <unk> 常常出現）表示模型在低頻詞處理上的局限性。\n","\n","**Discussion**\n","\n","　　從結果來看，transformer 模型在得到語言結構與生成文本表現不錯，但高測試 loss 和 perplexity 可看出模型的性能仍有提升空間。文本生成中出現的非連貫片段可能與訓練語料的規模有限及模型超參數調整不夠密切相關。此外，頻繁出現的 <unk> 可推論說詞彙表的設計和訓練數據的覆蓋範圍可能不足，導致模型對部分詞彙的學習效果不佳。未來可以透過增加訓練數據的規模、擴展詞彙表並進行更嚴謹的超參數調整來優化模型性能，也能嘗試更進階的 transformer 模型（如 GPT 或 BERT）可能進一步提升語言建模的效果。經過這次的作業，從數學基礎和程式撰寫實現上讓我對 transformer 結構更理解，也為日後進一步改進模型奠下良好基礎。"]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}